{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "spacy.load('en_core_web_lg')\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Public\\Projects\\huji_hackathon_22\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3369, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\ניצן\\AppData\\Local\\Temp\\ipykernel_21300\\3275634054.py\", line 2, in <cell line: 2>\n",
      "    transformers.AutoConfig\n",
      "  File \"C:\\Users\\Public\\Projects\\huji_hackathon_22\\venv\\lib\\site-packages\\transformers\\__init__.py\", line 2188, in __getattr__\n",
      "    \"TFXLNetModel\",\n",
      "  File \"C:\\Users\\Public\\Projects\\huji_hackathon_22\\venv\\lib\\site-packages\\transformers\\file_utils.py\", line 1490, in __getattr__\n",
      "  File \"C:\\Users\\Public\\Projects\\huji_hackathon_22\\venv\\lib\\site-packages\\transformers\\__init__.py\", line 2182, in _get_module\n",
      "    \"TFXLNetForMultipleChoice\",\n",
      "  File \"C:\\Users\\ניצן\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1030, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 972, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1030, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 986, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 680, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 855, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Public\\Projects\\huji_hackathon_22\\venv\\lib\\site-packages\\transformers\\models\\__init__.py\", line 19, in <module>\n",
      "    from . import (\n",
      "  File \"C:\\Users\\Public\\Projects\\huji_hackathon_22\\venv\\lib\\site-packages\\transformers\\models\\albert\\__init__.py\", line 21, in <module>\n",
      "    from ...utils import (\n",
      "ImportError: cannot import name '_LazyModule' from 'transformers.utils' (C:\\Users\\Public\\Projects\\huji_hackathon_22\\venv\\lib\\site-packages\\transformers\\utils\\__init__.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Public\\Projects\\huji_hackathon_22\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1982, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"C:\\Users\\Public\\Projects\\huji_hackathon_22\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\Public\\Projects\\huji_hackathon_22\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\Public\\Projects\\huji_hackathon_22\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\Public\\Projects\\huji_hackathon_22\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"C:\\Users\\Public\\Projects\\huji_hackathon_22\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"C:\\Users\\Public\\Projects\\huji_hackathon_22\\venv\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\Public\\Projects\\huji_hackathon_22\\venv\\lib\\site-packages\\stack_data\\core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"C:\\Users\\Public\\Projects\\huji_hackathon_22\\venv\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\Public\\Projects\\huji_hackathon_22\\venv\\lib\\site-packages\\stack_data\\core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"C:\\Users\\Public\\Projects\\huji_hackathon_22\\venv\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\Public\\Projects\\huji_hackathon_22\\venv\\lib\\site-packages\\stack_data\\core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"C:\\Users\\Public\\Projects\\huji_hackathon_22\\venv\\lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "# from transformers import AutoConfig\n",
    "transformers.AutoConfig\n",
    "print(\"1\")\n",
    "from transformers import FlaxAutoModelForSeq2SeqLM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MODEL_NAME_OR_PATH = \"flax-community/t5-recipe-generation\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME_OR_PATH, use_fast=True)\n",
    "model = FlaxAutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME_OR_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prefix = \"items: \"\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"max_length\": 512,\n",
    "    \"min_length\": 64,\n",
    "    \"no_repeat_ngram_size\": 3,\n",
    "    \"do_sample\": True,\n",
    "    \"top_k\": 60,\n",
    "    \"top_p\": 0.95\n",
    "}\n",
    "\n",
    "\n",
    "special_tokens = tokenizer.all_special_tokens\n",
    "tokens_map = {\n",
    "    \"<sep>\": \"--\",\n",
    "    \"<section>\": \"\\n\"\n",
    "}\n",
    "def skip_special_tokens(text, special_tokens):\n",
    "    for token in special_tokens:\n",
    "        text = text.replace(token, \"\")\n",
    "\n",
    "    return text\n",
    "\n",
    "def target_postprocessing(texts, special_tokens):\n",
    "    if not isinstance(texts, list):\n",
    "        texts = [texts]\n",
    "\n",
    "    new_texts = []\n",
    "    for text in texts:\n",
    "        text = skip_special_tokens(text, special_tokens)\n",
    "\n",
    "        for k, v in tokens_map.items():\n",
    "            text = text.replace(k, v)\n",
    "\n",
    "        new_texts.append(text)\n",
    "\n",
    "    return new_texts\n",
    "\n",
    "def generation_function(texts):\n",
    "    _inputs = texts if isinstance(texts, list) else [texts]\n",
    "    inputs = [prefix + inp for inp in _inputs]\n",
    "    inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=256,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"jax\"\n",
    "    )\n",
    "\n",
    "    input_ids = inputs.input_ids\n",
    "    attention_mask = inputs.attention_mask\n",
    "\n",
    "    output_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        **generation_kwargs\n",
    "    )\n",
    "    generated = output_ids.sequences\n",
    "    generated_recipe = target_postprocessing(\n",
    "        tokenizer.batch_decode(generated, skip_special_tokens=False),\n",
    "        special_tokens\n",
    "    )\n",
    "    return generated_recipe\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}